{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from classification import*\n",
    "from image_processing import*\n",
    "from utils import*\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all data \n",
    "import glob\n",
    "import random\n",
    "# using mpimg reading png, bins_range = (0, 1)\n",
    "cars = glob.glob('vehicles/*/*.png')  \n",
    "notcars = glob.glob('non-vehicles/*/*.png')\n",
    "\n",
    "print(\"Number of Cars-Samples:\",len(cars), '\\nNumber of NotCars-Samples:',len(notcars))\n",
    "\n",
    "tstcars = get_rand_samples(cars, 6)\n",
    "tstnotcars = get_rand_samples(notcars, 6)\n",
    "\n",
    "draw_pics(tstcars, titles=['car']*6)\n",
    "draw_pics(tstnotcars, titles=['notcar']*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = random.randint(0,len(cars)-1)\n",
    "car = mpimg.imread(cars[idx])\n",
    "notcar = mpimg.imread(notcars[idx])\n",
    "print(\"Size of test image: \", car.shape, 'idx:',idx)\n",
    "\n",
    "# preprocessing\n",
    "car *= 255\n",
    "car = car.astype(np.uint8)\n",
    "notcar *= 255\n",
    "notcar = notcar.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert color space\n",
    "car_ycc = convert_color(car, conv='RGB2YCrCb')\n",
    "notcar_ycc = convert_color(notcar, conv='RGB2YCrCb')\n",
    "\n",
    "car_luv = convert_color(car, conv='RGB2LUV')\n",
    "notcar_luv = convert_color(notcar, conv='RGB2LUV')\n",
    "\n",
    "car_hls = convert_color(car, conv='RGB2HLS')\n",
    "notcar_hls = convert_color(notcar, conv='RGB2HLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test for spatial bins diagram\n",
    "spatialcar_rgb = bin_spatial(car)\n",
    "spatialnotcar_rgb = bin_spatial(notcar)  \n",
    "spatialcar_ycc = bin_spatial(car_ycc)  \n",
    "spatialnotcar_ycc = bin_spatial(notcar_ycc)  \n",
    "spatialcar_luv = bin_spatial(car_luv)  \n",
    "spatialnotcar_luv = bin_spatial(notcar_luv)  \n",
    "spatialcar_hls = bin_spatial(car_hls)  \n",
    "spatialnotcar_hls = bin_spatial(notcar_hls) \n",
    "\n",
    "print(\"Number of spatial bins feature: \", len(spatialcar_rgb))\n",
    "plot_axes([spatialcar_rgb, spatialcar_ycc, spatialcar_luv, spatialcar_hls], \n",
    "          titles= ['spatial bins car(RGB)','spatial bins car(YCrCb)','spatial bins car(LUV)','spatial bins car(HLS)'])\n",
    "plot_axes([spatialnotcar_rgb, spatialnotcar_ycc, spatialnotcar_luv, spatialnotcar_hls], \n",
    "          titles= ['spatial bins notcar(RGB)','spatial bins notcar(YCrCb)',\n",
    "                   'spatial bins notcar(LUV)','spatial bins notcar(HLS)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test for color bins\n",
    "colorcar_rgb = color_hist(car)\n",
    "colornotcar_rgb = color_hist(notcar)\n",
    "colorcar_ycc = color_hist(car_ycc)\n",
    "colornotcar_ycc = color_hist(notcar_ycc)\n",
    "colorcar_luv = color_hist(car_luv)\n",
    "colornotcar_luv = color_hist(notcar_luv)\n",
    "colorcar_hls = color_hist(car_hls)\n",
    "colornotcar_hls = color_hist(notcar_hls)\n",
    "\n",
    "print(\"Number of hist feature: \", len(colorcar_rgb))\n",
    "plot_axes([colorcar_rgb, colorcar_ycc, colorcar_luv, colorcar_hls], \n",
    "          titles= [\"color hist diagram car(RGB)\",\"color hist diagram car(YCC)\",\n",
    "                   \"color hist diagram car(LUV)\",\"color hist diagram car(HLS)\"])\n",
    "plot_axes([colornotcar_rgb, colornotcar_ycc, colornotcar_luv, colornotcar_hls], \n",
    "          titles= [\"color hist diagram notcar(RGB)\",\"color hist diagram notcar(YCC)\",\n",
    "                   \"color hist diagram notcar(LUV)\",\"color hist diagram notcar(HLS)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test for HOG feature\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "def test_hog(img, orient, pix_per_cell, cell_per_block):\n",
    "    feat, hog0 = get_hog_features(img[:,:,0], orient, pix_per_cell, cell_per_block, visualise=True)\n",
    "    feat, hog1 = get_hog_features(img[:,:,1], orient, pix_per_cell, cell_per_block, visualise=True)\n",
    "    feat, hog2 = get_hog_features(img[:,:,2], orient, pix_per_cell, cell_per_block, visualise=True)\n",
    "    return hog0, hog1, hog2\n",
    "    \n",
    "hogcar_r, hogcar_g, hogcar_b = test_hog(car, orient, pix_per_cell, cell_per_block)\n",
    "hogcar_y, hogcar_cr, hogcar_cb = test_hog(car_ycc, orient, pix_per_cell, cell_per_block)\n",
    "hognotcar_r, hognotcar_g, hognotcar_b = test_hog(notcar, orient, pix_per_cell, cell_per_block)\n",
    "hognotcar_y, hognotcar_cr, hognotcar_cb = test_hog(notcar_ycc, orient, pix_per_cell, cell_per_block)\n",
    "\n",
    "draw_pics([car, hogcar_r, hogcar_g, hogcar_b, hogcar_y, hogcar_cr, hogcar_cb], \n",
    "          cmap=[None]+['gray']*6, titles=['car','R','G','B','Y','Cr','Cb'])\n",
    "draw_pics([notcar, hognotcar_r, hognotcar_g, hognotcar_b, hognotcar_y, hognotcar_cr, hognotcar_cb], \n",
    "          cmap=[None] + ['gray']*6,titles=['notcar','R','G','B','Y','Cr','Cb'])\n",
    "\n",
    "hogcar_l, hogcar_u, hogcar_v = test_hog(car_luv, orient, pix_per_cell, cell_per_block)\n",
    "hogcar_h, hogcar_l, hogcar_s = test_hog(car_hls, orient, pix_per_cell, cell_per_block)\n",
    "hognotcar_l, hognotcar_u, hognotcar_v = test_hog(notcar_luv, orient, pix_per_cell, cell_per_block)\n",
    "hognotcar_h, hognotcar_l, hognotcar_s = test_hog(notcar_hls, orient, pix_per_cell, cell_per_block)\n",
    "\n",
    "draw_pics([car, hogcar_l, hogcar_u, hogcar_v, hogcar_h, hogcar_l, hogcar_s], \n",
    "          cmap=[None]+['gray']*6, titles=['car','L','U','V','H','L','S'])\n",
    "draw_pics([notcar, hognotcar_l, hognotcar_u, hognotcar_v, hognotcar_h, hognotcar_l, hognotcar_s], \n",
    "          cmap=[None] + ['gray']*6,titles=['notcar','L','U','V','H','L','S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_hog_params(channel, orient=None, pix_per_cell=None, cell_per_block=None):\n",
    "    if orient is None:\n",
    "        orient_ = [5,6,7,8,9,10]\n",
    "        pix_per_cell_ = [8]*6\n",
    "        cell_per_block_ = [2]*6\n",
    "    if pix_per_cell is None:\n",
    "        pix_per_cell_ = [5,6,7,8,9,10]\n",
    "        orient_ = [9] * 6\n",
    "        cell_per_block_ = [2] * 6\n",
    "    if cell_per_block is None:\n",
    "        cell_per_block_ = [1, 2, 3, 4, 5, 6]\n",
    "        orient_ = [9]*6\n",
    "        pix_per_cell_=[8]*6\n",
    "    feats = []\n",
    "    hogs = []\n",
    "    titles = []\n",
    "    for i in range(6):\n",
    "        feat, hog = get_hog_features(channel, orient_[i], pix_per_cell_[i], cell_per_block_[i], visualise=True)\n",
    "        feats.append(feat)\n",
    "        hogs.append(hog)\n",
    "        if orient is None:\n",
    "            titles.append('orient={}'.format(i+5))\n",
    "        if pix_per_cell is None:\n",
    "            titles.append('pix_per_cell={}'.format(i+5))\n",
    "        if cell_per_block is None:\n",
    "            titles.append('cell_per_block={}'.format(i+1))\n",
    "        \n",
    "    return feats, hogs, titles\n",
    "\n",
    "feats, hogs, titles = test_hog_params(car_ycc[:,:,0], pix_per_cell=8, cell_per_block=2)\n",
    "draw_pics(hogs, cmap=['gray']*6, titles=titles)\n",
    "feats, hogs_pix, titles_pix = test_hog_params(car_ycc[:,:,0], orient=9, cell_per_block=2)\n",
    "draw_pics(hogs_pix, cmap=['gray']*6, titles=titles_pix)\n",
    "feats_cell, hogs_cell, titles_cell = test_hog_params(car_ycc[:,:,0], orient=9, pix_per_cell=8)\n",
    "plot_axes(feats_cell, titles=titles_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test all features\n",
    "featcar = single_img_features(car)\n",
    "featnotcar = single_img_features(notcar)\n",
    "\n",
    "plot_axes([featcar, featnotcar], titles=['Feature car (not normalized)', 'Feature notcar (not normalized)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test for scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# must have many datasets to compare with each other, so that the scaled data can be correct\n",
    "# singel feature cannot be scaled correctly\n",
    "\n",
    "X = np.vstack((featcar, featnotcar)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "print('Feature of single dataset: ', scaled_X[0].shape)\n",
    "plot_axes([scaled_X[0], scaled_X[1]],titles=['Feature car (normalized)', 'Feature notcar (normalized)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test for jpg format\n",
    "jpg = mpimg.imread('test.jpg')\n",
    "jpg = cv2.resize(jpg, (64,64))\n",
    "spatial_jpg = bin_spatial(jpg)  # size=(32,32)\n",
    "colorhist_jpg = color_hist(jpg)  # bins_range = (0, 256)\n",
    "jpg_ycc = convert_color(jpg, conv='RGB2YCrCb')\n",
    "feat_y_jpg, hogvis_jpg = get_hog_features(jpg_ycc[:,:,0], orient=9, pix_per_cell=8, cell_per_block=2, visualise=True)\n",
    "feat_jpg = single_img_features(jpg)  # in function automatically converted to ycrcb\n",
    "draw_pics([jpg, hogvis_jpg], cmap=[None, 'gray'], titles=['JPG image', 'HOG Image'])\n",
    "plot_axes([spatial_jpg, colorhist_jpg], titles=['Spatial bins', 'Color hist'])\n",
    "plot_axes([feat_y_jpg, feat_jpg], titles=['HOG features(Y ch)', 'All features(not normalized)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = False\n",
    "if test:\n",
    "    features_cars = extract_features_imglist(cars)\n",
    "    features_notcars = extract_features_imglist(notcars)\n",
    "    print('Number of datasets cars: ',len(features_cars))\n",
    "    print('Number of datasets notcars: ',len(features_notcars))\n",
    "    print('Feature of single dataset: ', features_cars[0].shape)\n",
    "else:\n",
    "    print(\"No test. Please set 'test' to True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = False\n",
    "if train:\n",
    "    svc, scaler, data = train_classifier(cars, notcars)\n",
    "else:\n",
    "    print(\"No Training. Please set 'train' to True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overridefile = False\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "filepath='mymodel.p'\n",
    "\n",
    "if not os.path.isfile(filepath) or overridefile:\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump((svc,scaler, data), f)\n",
    "        print(\"New file saved: \", filepath)\n",
    "else:\n",
    "    print('File already exists.')\n",
    "    print(\"When you want to override the saved file, please set 'overridefile' to True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load = True\n",
    "\n",
    "if load:\n",
    "    with open(filepath, 'rb') as f:\n",
    "        svc, scaler, data = pickle.load(f)\n",
    "        print('Model loaded.')\n",
    "else:\n",
    "    print(\"Model not loaded. Please set 'load' to True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data[0]\n",
    "y_train = data[2]\n",
    "X_test = data[1]\n",
    "y_test = data[3]\n",
    "predict_trained_model(svc, X_test, y_test, idx=list(range(0,20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from search_cars import*\n",
    "import time\n",
    "\n",
    "raw_img = mpimg.imread('test_images/test4.jpg')\n",
    "vanish_p = [raw_img.shape[1]//2, int(raw_img.shape[0]/100*58.3)]  # vanishing point\n",
    "\n",
    "wins_single_layer = gen_windows_single_layer(100, 0, raw_img.shape[1], raw_img.shape[0]//10*7, overlap=0.1)\n",
    "wins_img_single_layer = draw_boxes(raw_img, wins_single_layer)\n",
    "wins_all = gen_all_windows(raw_img, vanish_point=vanish_p, overlap=0.5)  \n",
    "# overlap val should be tuned, \n",
    "# overlap too small (close to 0.5) -> not enough windows\n",
    "# overlap too big (close to 1) ->  too many false windows\n",
    "wins_img_all = draw_boxes(raw_img, wins_all)\n",
    "\n",
    "# a full search\n",
    "overlap = 0.8\n",
    "n_layers = 5\n",
    "wins_all = gen_all_windows(raw_img, vanish_point=vanish_p, overlap=overlap, n_layers=n_layers)  \n",
    "t=time.time()\n",
    "on_wins = search_windows(raw_img, wins_all, svc, scaler)  # bins_range = (0, 256) because the img is .jpg\n",
    "t2 = time.time()\n",
    "print(\"time used: \", t2-t, \"s\")\n",
    "tst_img = draw_boxes(raw_img, on_wins)\n",
    "\n",
    "draw_pics([wins_img_single_layer, wins_img_all, tst_img], \n",
    "          titles=['Windows for one layer (Test)','All windows (Test)','All positive windows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heatmap = np.zeros_like(raw_img[:, :, 0]).astype(np.float)\n",
    "heatmap = add_heat(heatmap, on_wins)\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "threshold = 2  # need to be tuned\n",
    "heatmap_filtered = apply_threshold(heatmap, threshold)\n",
    "labels = label(heatmap_filtered)\n",
    "img_boxes = draw_labeled_bboxes(raw_img, labels)\n",
    "\n",
    "draw_pics([heatmap, heatmap_filtered, img_boxes], \n",
    "          titles=['Heatmap of positive windows','filterted heatmap','end effect'], \n",
    "          cmap=['gray', 'gray',None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from process_pipeline import *\n",
    "import time\n",
    "import glob\n",
    "imgs = glob.glob('test_images/*.jpg')\n",
    "\n",
    "overlap = 0.9\n",
    "threshold = 3\n",
    "n_layers = 6\n",
    "w_expand = 3\n",
    "p = Pipeline(vanish_p, overlap, svc, scaler, threshold, n_layers, w_expand)\n",
    "imgs_finish = []\n",
    "\n",
    "for img in imgs:\n",
    "    raw_img = mpimg.imread(img)\n",
    "    t = time.time()\n",
    "    im_finish = p.img_process(raw_img)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to process one single image: \", t2-t, \"s\", img)\n",
    "    imgs_finish.append(im_finish)\n",
    "\n",
    "draw_pics([img for img in imgs_finish[0:3]])\n",
    "draw_pics([img for img in imgs_finish[3:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_img = mpimg.imread('test_images/test4.jpg')\n",
    "on_wins = find_cars(raw_img, svc, scaler, cells_per_step=1)\n",
    "tst_img = draw_boxes(raw_img, on_wins)\n",
    "heatmap = np.zeros_like(tst_img[:, :, 0]).astype(np.float)\n",
    "heatmap = add_heat(heatmap, on_wins)\n",
    "\n",
    "draw_pics([tst_img, heatmap], titles=['All positive windows','Heatmap of positive windows'], cmap=[None, 'gray'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "# need to be tuned\n",
    "heatmap_filtered = apply_threshold(heatmap, threshold)\n",
    "labels = label(heatmap_filtered)\n",
    "img_boxes = draw_labeled_bboxes(raw_img, labels)\n",
    "draw_pics([heatmap_filtered, img_boxes], cmap=['gray', None], titles=['Filtered Heatmap','Image with box(boxes)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from process_pipeline import *\n",
    "imgs = glob.glob('test_images/*.jpg')\n",
    "\n",
    "threshold = 2\n",
    "cells_per_step = 1\n",
    "window = 64\n",
    "scale = 1.5\n",
    "p_subsam = Pipeline_subsamp(svc, scaler, threshold, cells_per_step=cells_per_step, window=window,scale=scale)\n",
    "\n",
    "imgs_finish = []\n",
    "\n",
    "for img in imgs:\n",
    "    raw_img = mpimg.imread(img)\n",
    "    t = time.time()\n",
    "    im_finish = p_subsam.img_process(raw_img)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to process one single image: \", t2-t, \"s\", img)\n",
    "    imgs_finish.append(im_finish)\n",
    "\n",
    "draw_pics([img for img in imgs_finish[0:3]])\n",
    "draw_pics([img for img in imgs_finish[3:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_subsam.expLabels=True\n",
    "raw_img = mpimg.imread('test_images/test1.jpg')\n",
    "labels = p_subsam.img_process(raw_img)\n",
    "newlabels = p_subsam.img_process_small(raw_img, labels)\n",
    "img_boxes = draw_labeled_bboxes(raw_img, newlabels)\n",
    "draw_pics([raw_img, img_boxes], titles=['raw image', 'with new labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "offset = 20\n",
    "org = Organizer(p_subsam, offset)\n",
    "\n",
    "output = 'result.mp4'\n",
    "\n",
    "clip_orig = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "if not os.path.isfile(output):\n",
    "    res_clip = clip_orig.fl_image(org.img_process) \n",
    "    %time res_clip.write_videofile(output, audio=False)\n",
    "else:\n",
    "    print('Video Already Exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\"\"\".format(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
